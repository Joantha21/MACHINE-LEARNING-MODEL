{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78cb020-f8e9-497a-9176-22693abc40aa",
   "metadata": {},
   "source": [
    "NEW ML MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a11df32-91cb-43fe-ba01-6403008270ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_740_b</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.256914</td>\n",
       "      <td>27.012462</td>\n",
       "      <td>-104.975629</td>\n",
       "      <td>13.605898</td>\n",
       "      <td>24.150483</td>\n",
       "      <td>0.025378</td>\n",
       "      <td>0.052282</td>\n",
       "      <td>0.301655</td>\n",
       "      <td>0.036793</td>\n",
       "      <td>0.083567</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.938971</td>\n",
       "      <td>104.946111</td>\n",
       "      <td>-51.973647</td>\n",
       "      <td>-51.973647</td>\n",
       "      <td>104.946111</td>\n",
       "      <td>-6.934144</td>\n",
       "      <td>95.104886</td>\n",
       "      <td>-49.061255</td>\n",
       "      <td>-49.061255</td>\n",
       "      <td>95.104886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.284621</td>\n",
       "      <td>9.265141</td>\n",
       "      <td>206.271960</td>\n",
       "      <td>16.874676</td>\n",
       "      <td>14.187340</td>\n",
       "      <td>17.981796</td>\n",
       "      <td>8.509174</td>\n",
       "      <td>68.098894</td>\n",
       "      <td>17.010031</td>\n",
       "      <td>18.935378</td>\n",
       "      <td>...</td>\n",
       "      <td>298.034311</td>\n",
       "      <td>212.532721</td>\n",
       "      <td>112.160233</td>\n",
       "      <td>112.160233</td>\n",
       "      <td>212.532721</td>\n",
       "      <td>281.040552</td>\n",
       "      <td>203.194976</td>\n",
       "      <td>106.486317</td>\n",
       "      <td>106.486317</td>\n",
       "      <td>203.194976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-61.300000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>-970.000000</td>\n",
       "      <td>-137.000000</td>\n",
       "      <td>-217.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-255.000000</td>\n",
       "      <td>-1360.000000</td>\n",
       "      <td>-203.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1180.000000</td>\n",
       "      <td>-921.000000</td>\n",
       "      <td>-504.000000</td>\n",
       "      <td>-504.000000</td>\n",
       "      <td>-921.000000</td>\n",
       "      <td>-1160.000000</td>\n",
       "      <td>-1010.000000</td>\n",
       "      <td>-521.000000</td>\n",
       "      <td>-521.000000</td>\n",
       "      <td>-1010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.577500</td>\n",
       "      <td>26.075000</td>\n",
       "      <td>-195.000000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>-3.105000</td>\n",
       "      <td>-1.340000</td>\n",
       "      <td>-4.002500</td>\n",
       "      <td>-2.905000</td>\n",
       "      <td>-2.622500</td>\n",
       "      <td>...</td>\n",
       "      <td>-106.500000</td>\n",
       "      <td>-8.365000</td>\n",
       "      <td>-92.900000</td>\n",
       "      <td>-92.900000</td>\n",
       "      <td>-8.365000</td>\n",
       "      <td>-102.500000</td>\n",
       "      <td>-8.837500</td>\n",
       "      <td>-87.150000</td>\n",
       "      <td>-87.150000</td>\n",
       "      <td>-8.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.100000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>-0.044600</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>-0.099750</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>...</td>\n",
       "      <td>83.850000</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>-21.800000</td>\n",
       "      <td>-21.800000</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>89.700000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>-24.100000</td>\n",
       "      <td>-24.100000</td>\n",
       "      <td>13.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.700000</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>6.735000</td>\n",
       "      <td>2.535000</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>...</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>149.250000</td>\n",
       "      <td>10.925000</td>\n",
       "      <td>10.925000</td>\n",
       "      <td>149.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>304.000000</td>\n",
       "      <td>42.300000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1070.000000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>888.000000</td>\n",
       "      <td>1670.000000</td>\n",
       "      <td>1670.000000</td>\n",
       "      <td>888.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        # mean_0_a     mean_1_a     mean_2_a     mean_3_a     mean_4_a  \\\n",
       "count  2132.000000  2132.000000  2132.000000  2132.000000  2132.000000   \n",
       "mean     15.256914    27.012462  -104.975629    13.605898    24.150483   \n",
       "std      15.284621     9.265141   206.271960    16.874676    14.187340   \n",
       "min     -61.300000  -114.000000  -970.000000  -137.000000  -217.000000   \n",
       "25%       6.577500    26.075000  -195.000000     4.857500    23.600000   \n",
       "50%      14.100000    30.000000    14.950000    15.400000    25.200000   \n",
       "75%      27.700000    31.400000    29.600000    26.500000    26.800000   \n",
       "max     304.000000    42.300000   661.000000   206.000000   213.000000   \n",
       "\n",
       "        mean_d_0_a   mean_d_1_a   mean_d_2_a   mean_d_3_a   mean_d_4_a  ...  \\\n",
       "count  2132.000000  2132.000000  2132.000000  2132.000000  2132.000000  ...   \n",
       "mean      0.025378     0.052282     0.301655     0.036793     0.083567  ...   \n",
       "std      17.981796     8.509174    68.098894    17.010031    18.935378  ...   \n",
       "min    -218.000000  -255.000000 -1360.000000  -203.000000  -553.000000  ...   \n",
       "25%      -3.105000    -1.340000    -4.002500    -2.905000    -2.622500  ...   \n",
       "50%      -0.044600     0.132000     0.957500    -0.099750     0.146500  ...   \n",
       "75%       2.920000     1.540000     6.735000     2.535000     2.870000  ...   \n",
       "max     402.000000   257.000000  1150.000000   349.000000   444.000000  ...   \n",
       "\n",
       "         fft_740_b    fft_741_b    fft_742_b    fft_743_b    fft_744_b  \\\n",
       "count  2132.000000  2132.000000  2132.000000  2132.000000  2132.000000   \n",
       "mean    -22.938971   104.946111   -51.973647   -51.973647   104.946111   \n",
       "std     298.034311   212.532721   112.160233   112.160233   212.532721   \n",
       "min   -1180.000000  -921.000000  -504.000000  -504.000000  -921.000000   \n",
       "25%    -106.500000    -8.365000   -92.900000   -92.900000    -8.365000   \n",
       "50%      83.850000    12.150000   -21.800000   -21.800000    12.150000   \n",
       "75%     154.000000   177.000000    12.025000    12.025000   177.000000   \n",
       "max    1070.000000   843.000000  1490.000000  1490.000000   843.000000   \n",
       "\n",
       "         fft_745_b    fft_746_b    fft_747_b    fft_748_b    fft_749_b  \n",
       "count  2132.000000  2132.000000  2132.000000  2132.000000  2132.000000  \n",
       "mean     -6.934144    95.104886   -49.061255   -49.061255    95.104886  \n",
       "std     281.040552   203.194976   106.486317   106.486317   203.194976  \n",
       "min   -1160.000000 -1010.000000  -521.000000  -521.000000 -1010.000000  \n",
       "25%    -102.500000    -8.837500   -87.150000   -87.150000    -8.837500  \n",
       "50%      89.700000    13.400000   -24.100000   -24.100000    13.400000  \n",
       "75%     153.000000   149.250000    10.925000    10.925000   149.250000  \n",
       "max    1180.000000   888.000000  1670.000000  1670.000000   888.000000  \n",
       "\n",
       "[8 rows x 2548 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "tf.keras.backend.clear_session()\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn import datasets, tree, linear_model, svm\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('emotions.csv')\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dae538d5-a0ea-44e5-882f-dc8a79968a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.620</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.60</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.700</td>\n",
       "      <td>2.060</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.50</td>\n",
       "      <td>20.300</td>\n",
       "      <td>20.300</td>\n",
       "      <td>23.50</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.800</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.80</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.880</td>\n",
       "      <td>3.830</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.30</td>\n",
       "      <td>-21.800</td>\n",
       "      <td>-21.800</td>\n",
       "      <td>-23.30</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.900</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.70</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.200</td>\n",
       "      <td>89.900</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.00</td>\n",
       "      <td>-233.000</td>\n",
       "      <td>-233.000</td>\n",
       "      <td>462.00</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.900</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.820</td>\n",
       "      <td>2.300</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.00</td>\n",
       "      <td>-243.000</td>\n",
       "      <td>-243.000</td>\n",
       "      <td>299.00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.300</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.060</td>\n",
       "      <td>41.400</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>38.100</td>\n",
       "      <td>38.100</td>\n",
       "      <td>12.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>32.400</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>30.80</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1.640</td>\n",
       "      <td>-2.030</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.70</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-21.70</td>\n",
       "      <td>95.2</td>\n",
       "      <td>-19.90</td>\n",
       "      <td>47.20</td>\n",
       "      <td>47.20</td>\n",
       "      <td>-19.90</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>16.300</td>\n",
       "      <td>31.3</td>\n",
       "      <td>-284.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>23.9</td>\n",
       "      <td>4.200</td>\n",
       "      <td>1.090</td>\n",
       "      <td>4.460</td>\n",
       "      <td>4.720</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>594.00</td>\n",
       "      <td>-324.000</td>\n",
       "      <td>-324.000</td>\n",
       "      <td>594.00</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>142.00</td>\n",
       "      <td>-59.80</td>\n",
       "      <td>-59.80</td>\n",
       "      <td>142.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>-0.547</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-259.0</td>\n",
       "      <td>15.80</td>\n",
       "      <td>26.7</td>\n",
       "      <td>9.080</td>\n",
       "      <td>6.900</td>\n",
       "      <td>12.700</td>\n",
       "      <td>2.030</td>\n",
       "      <td>4.64</td>\n",
       "      <td>...</td>\n",
       "      <td>370.00</td>\n",
       "      <td>-160.000</td>\n",
       "      <td>-160.000</td>\n",
       "      <td>370.00</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-169.00</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-169.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>16.800</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-288.0</td>\n",
       "      <td>8.34</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.460</td>\n",
       "      <td>1.580</td>\n",
       "      <td>-16.000</td>\n",
       "      <td>1.690</td>\n",
       "      <td>4.74</td>\n",
       "      <td>...</td>\n",
       "      <td>124.00</td>\n",
       "      <td>-27.600</td>\n",
       "      <td>-27.600</td>\n",
       "      <td>124.00</td>\n",
       "      <td>-656.0</td>\n",
       "      <td>552.00</td>\n",
       "      <td>-271.00</td>\n",
       "      <td>-271.00</td>\n",
       "      <td>552.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>27.000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.9</td>\n",
       "      <td>4.990</td>\n",
       "      <td>1.950</td>\n",
       "      <td>6.210</td>\n",
       "      <td>3.490</td>\n",
       "      <td>-3.51</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.810</td>\n",
       "      <td>1.810</td>\n",
       "      <td>1.95</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-6.71</td>\n",
       "      <td>22.80</td>\n",
       "      <td>22.80</td>\n",
       "      <td>-6.71</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2132 rows × 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  \\\n",
       "0          4.620      30.3    -356.0     15.60      26.3       1.070   \n",
       "1         28.800      33.1      32.0     25.80      22.8       6.550   \n",
       "2          8.900      29.4    -416.0     16.70      23.7      79.900   \n",
       "3         14.900      31.6    -143.0     19.80      24.3      -0.584   \n",
       "4         28.300      31.3      45.2     27.30      24.5      34.800   \n",
       "...          ...       ...       ...       ...       ...         ...   \n",
       "2127      32.400      32.2      32.2     30.80      23.4       1.640   \n",
       "2128      16.300      31.3    -284.0     14.30      23.9       4.200   \n",
       "2129      -0.547      28.3    -259.0     15.80      26.7       9.080   \n",
       "2130      16.800      19.9    -288.0      8.34      26.0       2.460   \n",
       "2131      27.000      32.0      31.8     25.00      28.9       4.990   \n",
       "\n",
       "      mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  \\\n",
       "0          0.411     -15.700       2.060        3.15  ...      23.50   \n",
       "1          1.680       2.880       3.830       -4.82  ...     -23.30   \n",
       "2          3.360      90.200      89.900        2.03  ...     462.00   \n",
       "3         -0.284       8.820       2.300       -1.97  ...     299.00   \n",
       "4         -5.790       3.060      41.400        5.52  ...      12.00   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2127      -2.030       0.647      -0.121       -1.10  ...     -21.70   \n",
       "2128       1.090       4.460       4.720        6.63  ...     594.00   \n",
       "2129       6.900      12.700       2.030        4.64  ...     370.00   \n",
       "2130       1.580     -16.000       1.690        4.74  ...     124.00   \n",
       "2131       1.950       6.210       3.490       -3.51  ...       1.95   \n",
       "\n",
       "      fft_742_b  fft_743_b  fft_744_b  fft_745_b  fft_746_b  fft_747_b  \\\n",
       "0        20.300     20.300      23.50     -215.0     280.00    -162.00   \n",
       "1       -21.800    -21.800     -23.30      182.0       2.57     -31.60   \n",
       "2      -233.000   -233.000     462.00     -267.0     281.00    -148.00   \n",
       "3      -243.000   -243.000     299.00      132.0     -12.40       9.53   \n",
       "4        38.100     38.100      12.00      119.0     -17.60      23.90   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2127      0.218      0.218     -21.70       95.2     -19.90      47.20   \n",
       "2128   -324.000   -324.000     594.00      -35.5     142.00     -59.80   \n",
       "2129   -160.000   -160.000     370.00      408.0    -169.00     -10.50   \n",
       "2130    -27.600    -27.600     124.00     -656.0     552.00    -271.00   \n",
       "2131      1.810      1.810       1.95      110.0      -6.71      22.80   \n",
       "\n",
       "      fft_748_b  fft_749_b     label  \n",
       "0       -162.00     280.00  NEGATIVE  \n",
       "1        -31.60       2.57   NEUTRAL  \n",
       "2       -148.00     281.00  POSITIVE  \n",
       "3          9.53     -12.40  POSITIVE  \n",
       "4         23.90     -17.60   NEUTRAL  \n",
       "...         ...        ...       ...  \n",
       "2127      47.20     -19.90   NEUTRAL  \n",
       "2128     -59.80     142.00  POSITIVE  \n",
       "2129     -10.50    -169.00  NEGATIVE  \n",
       "2130    -271.00     552.00  NEGATIVE  \n",
       "2131      22.80      -6.71   NEUTRAL  \n",
       "\n",
       "[2132 rows x 2549 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c26dc90e-2d73-457e-8d68-ddb8597ec35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separarting Positive, Neagtive and Neutral dataframes:\n",
    "pos = data.loc[data[\"label\"]==\"POSITIVE\"]\n",
    "sample_pos = pos.loc[2, 'fft_0_b':'fft_749_b']\n",
    "neg = data.loc[data[\"label\"]==\"NEGATIVE\"]\n",
    "sample_neg = neg.loc[0, 'fft_0_b':'fft_749_b']\n",
    "neu = data.loc[data[\"label\"]==\"NEUTRAL\"]\n",
    "sample_neu = neu.loc[1, 'fft_0_b':'fft_749_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2ec43a80-2466-4daa-a1b4-b27c52b87c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transform_data(data):\n",
    "    #Encoding Lables into numbers\n",
    "    encoding_data = ({'NEUTRAL': 0, 'POSITIVE': 1, 'NEGATIVE': 2} )\n",
    "    data_encoded = data.replace(encoding_data)\n",
    "    #getting brain signals into x variable\n",
    "    x=data_encoded.drop([\"label\"]  ,axis=1)\n",
    "    #getting labels into y variable\n",
    "    y = data_encoded.loc[:,'label'].values\n",
    "    scaler = StandardScaler()\n",
    "    #scaling Brain Signals\n",
    "    scaler.fit(x)\n",
    "    X = scaler.transform(x)\n",
    "    #One hot encoding Labels \n",
    "    Y = to_categorical(y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e0c0b9f4-a92c-456f-a62c-fe5e6c7f7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling above function and splitting dataset into train and test\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "X,Y = Transform_data(data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e4c2b5ee-d85e-4c0f-b15f-1a53cb534ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2548"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eec8703c-ae24-4e04-973c-b0069ba587b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1705"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0e298f6c-cd0c-4f71-a530-3525182feba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train); x_test = np.asarray(x_test)\n",
    "y_train = np.asarray(y_train); y_test = np.asarray(y_test)\n",
    "\n",
    "num_classes = int(np.unique(y_train).size)\n",
    "assert y_train.shape[1] == 3\n",
    "num_classes = 3\n",
    "\n",
    "def create_model(input_dim, num_classes, model_name=\"Daddy\"):\n",
    "    # inputs  = layers.Input(shape = (input_dim, ), name = \"inputs\")\n",
    "    # x       = layers.Reshape((input_dim, 1), name = \"expand_dim\")(inputs)\n",
    "    # x       = layers.GRU(256, return_sequences = True, name = \"gru\")(x)\n",
    "    # x       = layers.Lambda(lambda t: t[:, -1, :], name = 'collapse')(x)\n",
    "    # x       = layers.Dropout(0.5, name = \"dropout\")(x)\n",
    "    # outputs = layers.Dense(num_classes, activation = \"softmax\", name = \"classifier\")(x)\n",
    "    inputs = layers.Input(shape = (input_dim,), name = \"inputs\")\n",
    "    x = layers.Lambda(lambda t: tf.expand_dims(t, axis = -1), name = \"expand_dims\")(inputs)  \n",
    "    x = layers.GRU(256, return_sequences = True, name = \"gru\")(x)  \n",
    "    x = layers.Flatten(name = \"flatten\")(x)                      \n",
    "    outputs = layers.Dense(num_classes, activation = \"softmax\", name = \"dense\")(x)\n",
    "    \n",
    "    return Model(inputs, outputs, name = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e180a186-c6e1-42c2-8091-95320470c927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Daddy\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Daddy\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2548</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ expand_dims (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2548</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2548</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">198,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">652288</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,956,867</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inputs (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2548\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ expand_dims (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2548\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2548\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m198,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m652288\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │     \u001b[38;5;34m1,956,867\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155,779</span> (8.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,155,779\u001b[0m (8.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155,779</span> (8.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,155,779\u001b[0m (8.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DaddyChill = create_model(x_train.shape[1], num_classes)\n",
    "DaddyChill.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "DaddyChill.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d93884-b474-4b77-9ab5-347fc197d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m22/48\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m17:22\u001b[0m 40s/step - accuracy: 0.7418 - loss: 1.0179"
     ]
    }
   ],
   "source": [
    "#Training and Evaluting model\n",
    "history = DaddyChill.fit(x_train, y_train, epochs = 10, validation_split = 0.1)\n",
    "loss, acc = DaddyChill.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e88c6-8e9b-4cc9-b0ef-a39a6011edc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
